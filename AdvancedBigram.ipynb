{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ef2fc56-4430-4251-9695-6aefb28c8fdb",
   "metadata": {},
   "source": [
    "# Generate words 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb961cea-c399-4fd7-87d9-f174a4cfdaec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /home/a/.local/lib/python3.13/site-packages (2.8.0)\n",
      "Requirement already satisfied: filelock in /home/a/.local/lib/python3.13/site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/a/.local/lib/python3.13/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3.13/site-packages (from torch) (74.1.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/a/.local/lib/python3.13/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/a/.local/lib/python3.13/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/a/.local/lib/python3.13/site-packages (from torch) (2025.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/a/.local/lib/python3.13/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/a/.local/lib/python3.13/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/a/.local/lib/python3.13/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/a/.local/lib/python3.13/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/a/.local/lib/python3.13/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/a/.local/lib/python3.13/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/a/.local/lib/python3.13/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/a/.local/lib/python3.13/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/a/.local/lib/python3.13/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/a/.local/lib/python3.13/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /home/a/.local/lib/python3.13/site-packages (from torch) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/a/.local/lib/python3.13/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/a/.local/lib/python3.13/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/a/.local/lib/python3.13/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /home/a/.local/lib/python3.13/site-packages (from torch) (3.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/a/.local/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib64/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in /usr/lib64/python3.13/site-packages (3.10.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/lib64/python3.13/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/lib/python3.13/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/lib64/python3.13/site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/lib64/python3.13/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in /home/a/.local/lib/python3.13/site-packages (from matplotlib) (2.2.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3.13/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/lib64/python3.13/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/a/.local/lib/python3.13/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/lib/python3.13/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "\n",
      "\n",
      "\u001b7\u001b[1A\u001b[1G\u001b[27G[Files: 0  Bytes: 0  [0 B/s] Re]\u001b8\u001b7\u001b[2A\u001b[1G\u001b[27G[https://gist.githubusercontent]\u001b8\u001b7\u001b[1S\u001b[3A\u001b[1G\u001b[0JSaving 'last-names.txt.4'\n",
      "\u001b8\u001b7\u001b[2A\u001b[1Glast-names.txt.4      28% [=======>                      ]  190.55K    --.-KB/s\u001b8\u001b7\u001b[1A\u001b[1G\u001b[27G[Files: 0  Bytes: 0  [0 B/s] Re]\u001b8\u001b7\u001b[2A\u001b[1Glast-names.txt.4     100% [=============================>]  679.12K    4.41MB/s\u001b8\u001b7\u001b[1S\u001b[3A\u001b[1G\u001b[0JHTTP response 200  [https://gist.githubusercontent.com/craigmartin97/e98a9e2a267c379e47be1191d9431de2/raw/c09c7356e85e39e41faa92a665b7ef0b3b840b6a/last-names.txt]\n",
      "\u001b8\u001b7\u001b[2A\u001b[1Glast-names.txt.4     100% [=============================>]  679.12K    4.41MB/s\u001b8\u001b7\u001b[1A\u001b[1G\u001b[27G[Files: 1  Bytes: 679.12K [610.]\u001b8\u001b[m\u001b[m\u001b[m\u001b[m"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install matplotlib\n",
    "!wget https://gist.githubusercontent.com/craigmartin97/e98a9e2a267c379e47be1191d9431de2/raw/c09c7356e85e39e41faa92a665b7ef0b3b840b6a/last-names.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64719264-7968-4539-a79b-a5bfd44ae581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "458ce400-f87e-42fb-b2e6-1257146aa369",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'blk_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m text = \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mlast-names.txt\u001b[39m\u001b[33m\"\u001b[39m).read()\n\u001b[32m      2\u001b[39m raw_names = text.splitlines()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m raw_names = [\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m * (\u001b[43mblk_size\u001b[49m) + name + \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m raw_names]\n\u001b[32m      4\u001b[39m vocab = \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(text + \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)))\n\u001b[32m      5\u001b[39m N = \u001b[38;5;28mlen\u001b[39m(vocab)\n",
      "\u001b[31mNameError\u001b[39m: name 'blk_size' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "text = open(\"last-names.txt\").read()\n",
    "raw_names = text.splitlines()\n",
    "raw_names = [\".\" * (blk_size) + name + \".\" for name in raw_names]\n",
    "vocab = sorted(list(set(text + \".\")))\n",
    "N = len(vocab)\n",
    "itc = dict(list(enumerate(vocab)))\n",
    "cti = {v: k for k, v in itc.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44d2047-60ec-4163-8e88-d7e22d8125c6",
   "metadata": {},
   "source": [
    "### Create the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4e23dd-74b4-4d79-af02-5911bb303cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "blk_size = 3\n",
    "for name in raw_names:\n",
    "    for ix in range(len(name) - blk_size):\n",
    "        x = []\n",
    "        for jx in range(blk_size):\n",
    "            x.append(cti[name[ix+jx]])\n",
    "        X.append(x)\n",
    "        Y.append(cti[name[ix+blk_size]])\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)\n",
    "Xtr, Ytr = X[:int(len(X) * 0.8)], Y[:int(len(Y) * 0.8)]\n",
    "Xdev, Ydev = X[int(len(X) * 0.8):int(len(X) * 0.9)], Y[int(len(X) * 0.8):int(len(Y) * 0.9)]\n",
    "Xval, Yval = X[int(len(X) * 0.9):], Y[int(len(X) * 0.8):]\n",
    "\n",
    "print(Xtr.shape, Ytr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e78f85e-3681-40f6-a279-b57d936e615d",
   "metadata": {},
   "source": [
    "### Create the embeddings\n",
    "\n",
    "`C` is the lookup table to create the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2685d09-32a1-4516-bb17-3383e981a14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dims = 12\n",
    "C = torch.randn((N, emb_dims))\n",
    "sample = X[:3]\n",
    "print(sample)\n",
    "emb = C[sample]\n",
    "print(emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea9b402-c9f8-403d-884e-0149e744aabe",
   "metadata": {},
   "source": [
    "Now we create the first FC layer, to take the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cba533-efcc-46a5-8695-ae90f0e0c06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = torch.randn((emb_dims * blk_size, 200)) * 0.1\n",
    "b1 = torch.randn(200) * 0.1\n",
    "# here a tanh\n",
    "W2 = torch.randn((200, N)) * 0.1\n",
    "b2 = torch.randn(N) * 0.1\n",
    "# softmax\n",
    "\n",
    "emb = emb.view(-1, blk_size * emb_dims)\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1351cf-4cbe-4080-b904-c8657fc93c85",
   "metadata": {},
   "source": [
    "This is how you would do a single forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dc54d5-18ae-4215-acf0-95cbd3e4bba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = emb @ W1 + b1\n",
    "a = F.tanh(a)\n",
    "a = a @ W2 + b2\n",
    "print(a.shape)\n",
    "a = F.softmax(a, 1)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87798c82-6bc0-4e73-8191-fd99eb5c75de",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [C, W1, b1, W2, b2]\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a77355-75a9-474f-af48-db78f75a3571",
   "metadata": {},
   "source": [
    "Lets do the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4886e3f2-5453-4da4-97b3-1ce59f4a9e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7084a3-3c5c-47aa-b4fe-de1b56c4a546",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(Xtr))\n",
    "loss_t = 0\n",
    "ix = 1\n",
    "for i in range(200000):\n",
    "    batch_ix = torch.randint(0, len(Xtr), (32,))\n",
    "\n",
    "    emb = C[Xtr[batch_ix]]\n",
    "    emb = emb.view(-1, blk_size * emb_dims)\n",
    "\n",
    "    h = F.tanh(emb @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    # probs = F.softmax(logits, 1)\n",
    "    loss = F.cross_entropy(logits, Ytr[batch_ix])\n",
    "    lr = 0.01 if i < 100000 else 0.01\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    \n",
    "    loss.backward()\n",
    "    loss_t += loss.item()\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "    if ix % 20000 == 0:\n",
    "        print(f\"{loss_t/ix=}\")\n",
    "\n",
    "    ix += 1\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f8f6bb-254d-45c0-969f-3ea4d5c4c91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(logits.detach().numpy())\n",
    "\n",
    "plt.hist(h.detach().numpy())\n",
    "# plt.imshow(h.detach().numpy() > 0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76df37e9-f0b6-402b-8a69-7a2e2a2db739",
   "metadata": {},
   "source": [
    "Now let's use the dev dataset to check our results and tune our hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906c59aa-09af-45a0-8d1d-8f42a1bfaee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    emb = C[Xdev]\n",
    "    emb = emb.view(-1, blk_size * emb_dims)\n",
    "    \n",
    "    h = F.tanh(emb @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    # probs = F.softmax(logits, 1)\n",
    "    loss = F.cross_entropy(logits, Ydev)\n",
    "    print(f\"{loss=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d7bb07-b79b-4b5a-a587-2bbc6975c779",
   "metadata": {},
   "source": [
    "Lets generate some words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bf7497-3755-46a2-8bbb-a02b55545582",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    sample = torch.tensor([1, 1,  1])\n",
    "    out = \"\"\n",
    "    while True:\n",
    "        emb = C[sample]\n",
    "        emb = emb.view(-1, blk_size * emb_dims)\n",
    "        \n",
    "        h = F.tanh(emb @ W1 + b1)\n",
    "        logits = h @ W2 + b2\n",
    "        probs = F.softmax(logits, 1)\n",
    "        y = torch.multinomial(probs, num_samples=1, replacement=True)\n",
    "        sample = sample[1:]\n",
    "        sample = torch.cat((sample, torch.tensor([y])), 0)\n",
    "        \n",
    "        if y == 1:\n",
    "            break\n",
    "        out += itc[y.item()]\n",
    "        \n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d3435a-6c44-4b7d-b304-be5818d5c705",
   "metadata": {},
   "source": [
    "## Some names generated my the model\n",
    "* WALFAILMAN\n",
    "* TATTIN\n",
    "* DUS\n",
    "* SETTE\n",
    "* BURG\n",
    "* MAGNIS\n",
    "* GORD\n",
    "* HURN\n",
    "* QUISGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754223b7-6158-4a22-8c2b-43a1c4695cf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc997f0f-e76d-47bf-ab87-bc4e62ed54a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06660726-7909-4380-9b4d-f5471b36e8eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8726f89-ddef-41d1-9457-3550229e7693",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
